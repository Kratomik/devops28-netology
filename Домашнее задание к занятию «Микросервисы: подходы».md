# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

- Ответ:

```Bash
По условиям задания мы строим систему с нуля, поэтому в качестве решения я бы выбрал GitLab. Он поддерживает выдвинутые требования, имеет большое сообщество, все будет централизованно в одной системе, поддерживает интеграции с другими системами, которые могут понадобится по мере роста проекта. Большим плюсом является возможность развернуть GitLab EE на своих мощностях, что актуально в наше время.
Для безопасного хранения секретов можно связать GitLab с Hashicorp Vault.
```

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

- Ответ:

Стандартным enterprise решением является стэк ELK (Elasticsearch, Logstash,Kibana, FileBeat). Это самый популярный стэк с большим сообществом, хорошо масштабируется, отказоустойчив.  
Состав стэка:

* Elasticsearch - NoSQL СУБД и поисковая система
* Logstash - средство обработки, преобразования и сохранения логов из различных источников
* Kibana - инструмент визуализации и изучения данных
* FileBeat - агент для сбора и отправки данных в Logstash

Минусом данного стэка является высокое требование к ресурсам. Если ресурсов не так много, то можно рассмотреть стэк для сбора логов состоящий из Loki, Promtail, Grafana.   
Loki по сравнению с Elasticsearch потребляет меньше памяти, т.к. написан на GO. Язык запросов LogQL используемый в Grafana Loki похож на популярный PromQL, что будет плюсом. Легко интегрируется с такими популярными инструментам, как Kubernetes, Prometheus.

Состав стэка Loki, Promtail, Grafana:
* Loki - хранит и обрабатывает логи
* Promtail - собирает логи, обрабатывает их и отправляет в Loki
* Grafana - инструмент визуализации и изучения данных

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

 - Ответ:

Предлагаю стэк Prometheus, Grafana.  
Данный стек популярен для мониторинга кластеров Kubernetes, поддерживает требования выше. Все компоненты стека давно на рынке и имеют большое сообщество, потребляют мало ресурсов, большинство специалистов имеют опыт работы с данными продуктами, что позволит задействовать мониторинг оперативно.

Prometheus - представляет из себя набор компонентов для мониторинга, уже является коробным решением для мониторинга, т.к. включает в себя:

* Exporter - агент для сборки метрик с хост-машин и хранения до сбора системой мониторинга
* Server - хранение данных и их менеджмент
* Web UI - веб интерфейс для доступа к данным и конфигурирования системы
* Alert Manager - система оповещения

Grafana - инструмент визуализации и изучения данных. Позволит создавать информативные и красивые дашборды с нужными нам метриками.

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
